// lib/ai/providers/openai-compat.ts
// OpenAI-compatible provider â€” works with OpenRouter AND Ollama via Olla
import OpenAI from 'openai'
import type { AIService, DocumentMetadata } from '../types'
import { logger } from '@/lib/logging/redact'
import { withRetry } from '../utils'

export interface OpenAICompatConfig {
    baseURL: string      // 'https://openrouter.ai/api/v1' or Olla endpoint
    apiKey: string
    chatModel: string    // 'google/gemini-2.5-flash', 'llama3.3:70b', etc.
    embedModel: string   // 'nomic-embed-text', or fallback to Gemini
    providerName: string
}

export class OpenAICompatService implements AIService {
    readonly providerName: string
    readonly embeddingModel: string
    private client: OpenAI
    private chatModel: string

    constructor(config: OpenAICompatConfig) {
        this.providerName = config.providerName
        this.embeddingModel = config.embedModel
        this.chatModel = config.chatModel
        this.client = new OpenAI({
            baseURL: config.baseURL,
            apiKey: config.apiKey,
            defaultHeaders: {
                // OpenRouter requires these headers
                'HTTP-Referer': 'https://diamond-kms.app',
                'X-Title': 'DIAMOND KMS',
            },
        })
    }

    async generateEmbedding(text: string): Promise<number[]> {
        return withRetry(async () => {
            try {
                // console.log(`[AI-SELFHOSTED] Generating embedding for text length: ${text.length}`)
                const response = await this.client.embeddings.create({
                    model: this.embeddingModel,
                    input: text,
                })
                const embedding = response.data[0]?.embedding
                if (!embedding) throw new Error('No embedding returned from provider')
                return embedding
            } catch (err: any) {
                // If the provider doesn't support embeddings (like Olla), fallback to Gemini
                if (err.status === 404 || err.message?.includes('404')) {
                    logger.warn(`Provider ${this.providerName} doesn't support embeddings, falling back to Gemini.`)
                    console.log(`[AI-SELFHOSTED] Fallback to Gemini for embeddings`)
                    const { env } = await import('@/lib/env')
                    if (!env.GEMINI_API_KEY) throw new Error('GEMINI_API_KEY required for fallback embeddings')
                    const { GoogleGenerativeAI } = await import('@google/generative-ai')
                    const genAI = new GoogleGenerativeAI(env.GEMINI_API_KEY)
                    const model = genAI.getGenerativeModel({ model: 'text-embedding-004' })
                    const res = await model.embedContent(text)
                    return res.embedding.values
                }
                console.error(`[AI-SELFHOSTED] Embedding Error:`, err.message)
                throw err
            }
        })
    }

    async generateCompletion(
        prompt: string,
        options?: { systemPrompt?: string; maxTokens?: number; jsonMode?: boolean }
    ): Promise<string> {
        return withRetry(async () => {
            console.log(`[AI-SELFHOSTED] Generating completion. Model: ${this.chatModel}, Prompt length: ${prompt.length}`)
            const startTime = Date.now()
            const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = []
            if (options?.systemPrompt) {
                messages.push({ role: 'system', content: options.systemPrompt })
            }
            messages.push({ role: 'user', content: prompt })

            const requestBody: any = {
                model: this.chatModel,
                max_tokens: options?.maxTokens ?? 2048,
                response_format: options?.jsonMode ? { type: 'json_object' } : undefined,
                messages,
                temperature: 0.7,
                frequency_penalty: 0.5,
                presence_penalty: 0.1,
                repetition_penalty: 1.15,
            }

            try {
                const response = await this.client.chat.completions.create(requestBody)
                console.log(`[AI-SELFHOSTED] Completion finished in ${Date.now() - startTime}ms`)
                return response.choices[0]?.message.content ?? ''
            } catch (err: any) {
                console.error(`[AI-SELFHOSTED] Completion Error after ${Date.now() - startTime}ms:`, err.message)
                throw err
            }
        })
    }

    async streamCompletion(
        prompt: string,
        systemPrompt: string,
        onChunk: (chunk: string) => void,
        signal?: AbortSignal
    ): Promise<void> {
        const requestBody: any = {
            model: this.chatModel,
            stream: true,
            messages: [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: prompt },
            ],
            temperature: 0.7,
            frequency_penalty: 0.5,
            presence_penalty: 0.1,
            repetition_penalty: 1.15,
        }

        const stream = await this.client.chat.completions.create(
            requestBody,
            { signal }
        ) as unknown as AsyncIterable<any>
        for await (const chunk of stream) {
            const text = chunk.choices[0]?.delta.content ?? ''
            if (text) onChunk(text)
        }
    }

    async generateDocumentMetadata(
        input: { text?: string; fileBuffer?: Buffer; fileName: string }
    ): Promise<DocumentMetadata> {
        const content = input.text ?? `[File: ${input.fileName}]`
        const safeContent = content.slice(0, 2500)
        console.log(`[AI-SELFHOSTED] Generating metadata for document: ${input.fileName}, text length: ${safeContent.length}`)
        const raw = await this.generateCompletion(
            `Document content:\n${safeContent}`,
            {
                systemPrompt:
                    'You analyze documents. Return ONLY valid JSON with fields: title (string, max 80 chars), summary (string, 2-3 paragraphs), tags (string array, 5 items), language ("id"|"en"|"mixed"), docType ("sop"|"policy"|"guide"|"report"|"regulation"|"other")',
                jsonMode: true,
            }
        )

        try {
            const parsed = JSON.parse(raw) as DocumentMetadata
            console.log(`[AI-SELFHOSTED] Metadata parse SUCCESS:`, parsed.title)
            return parsed
        } catch (parseError) {
            logger.error('Failed to parse metadata response:', raw)
            console.log(`[AI-SELFHOSTED] Metadata parse FAILED. Raw output:`, raw.substring(0, 100))
            return {
                title: input.fileName.replace(/\.[^/.]+$/, '').replace(/[-_]/g, ' '),
                summary: content.slice(0, 200),
                tags: ['document'],
                language: 'id',
                docType: 'other',
            }
        }
    }
}
